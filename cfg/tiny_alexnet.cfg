[net]
batch=128
subdivisions=1
height=224
width=224
channels=3
min_crop=224
max_crop=224

hue=.1
saturation=.75
exposure=.75

# FP training epochs
# 781.25 steps per epoch
max_batches=78125 # 100 epochs

# Optimizer
policy=step
step=15625 # every 20 epochs
scale=0.1
learning_rate=0.005 # FP training
#learning_rate=0.0001 # INT4 training
momentum=0.9
decay=0.0

// cluster qat
#policy=constant
#learning_rate=0.000001

qat_init_step=1
qat_end_epoch=1
ema_smooth=0.999     # smoothing parameter
ema_decay=0          # boolean factor to on/off
ema_convergence=0.999 # sparam at the end of qat

# size ref: tf benchmark
[convolutional]
filters=64
size=11
stride=4
activation=relu

[maxpool]
size=3
stride=2

[convolutional]
filters=192
size=5
stride=1
pad=1
activation=relu

[maxpool]
size=3
stride=2

[convolutional]
filters=384
size=3
stride=1
pad=1
activation=relu

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu

[maxpool]
size=3
stride=2

[connected]
output=4096
activation=relu

[connected]
output=4096
activation=relu

[connected]
output=200
activation=linear

[softmax]
groups=1
